{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71fed9aa",
   "metadata": {},
   "source": [
    "# Layer of Neurons & Batch of Data with NumPy\n",
    "\n",
    "Previously we:\n",
    "\n",
    "- computed a single layer’s output for **one sample** using NumPy:\n",
    "  - `np.dot(weights, inputs) + biases`\n",
    "- introduced **batches** of samples (inputs as a matrix)\n",
    "- learned that matrix multiplication is just a **grid of dot products**\n",
    "\n",
    "Now we combine all of this:\n",
    "\n",
    "- inputs → a **batch** of samples (matrix)\n",
    "- weights → a **layer** of neurons (matrix)\n",
    "- biases → one bias per neuron (vector)\n",
    "\n",
    "We’ll use:\n",
    "\n",
    "$$\n",
    "\\text{layer\\_outputs} = X \\cdot W^T + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $X$ has shape $(\\text{batch\\_size}, \\text{n\\_features})$\n",
    "- $W$ has shape $(\\text{n\\_neurons}, \\text{n\\_features})$\n",
    "- $W^T$ has shape $(\\text{n\\_features}, \\text{n\\_neurons})$\n",
    "- $\\mathbf{b}$ has shape $(\\text{n\\_neurons},)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da430a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer outputs:\n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Batch of 3 input samples, 4 features each\n",
    "inputs = [\n",
    "    [1.0,  2.0,  3.0,  2.5],\n",
    "    [2.0,  5.0, -1.0,  2.0],\n",
    "    [-1.5, 2.7,  3.3, -0.8]\n",
    "]\n",
    "\n",
    "# 3 neurons, each with 4 weights (one per input feature)\n",
    "weights = [\n",
    "    [0.2,   0.8,  -0.5,  1.0],\n",
    "    [0.5,  -0.91,  0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17,  0.87]\n",
    "]\n",
    "\n",
    "# One bias per neuron\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "# Convert weights to a NumPy array so we can transpose them\n",
    "weights = np.array(weights)\n",
    "\n",
    "layer_outputs = np.dot(inputs, weights.T) + biases\n",
    "\n",
    "print(\"Layer outputs:\\n\", layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea23e3a",
   "metadata": {},
   "source": [
    "## Shapes and Why We Transpose the Weights\n",
    "\n",
    "Let’s inspect the shapes.\n",
    "\n",
    "- `inputs` → batch of 3 samples, each with 4 features  \n",
    "  → shape: $(3, 4)$\n",
    "\n",
    "- `weights` → 3 neurons, each with 4 weights  \n",
    "  → shape: $(3, 4)$\n",
    "\n",
    "We want:\n",
    "\n",
    "- for each **sample** (row of `inputs`)\n",
    "- to get outputs from each **neuron** (row of `weights`)\n",
    "\n",
    "For matrix multiplication:\n",
    "\n",
    "- we need $(\\text{batch\\_size}, \\text{n\\_features}) \\cdot (\\text{n\\_features}, \\text{n\\_neurons})$\n",
    "- so we transpose `weights` from shape $(3, 4)$ to $(4, 3)$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "(3, 4) \\times (4, 3) \\rightarrow (3, 3)\n",
    "$$\n",
    "\n",
    "So the result has shape:\n",
    "\n",
    "- $(\\text{batch\\_size}, \\text{n\\_neurons})$\n",
    "- here: 3 samples × 3 neurons → $(3, 3)$\n",
    "\n",
    "Each **row** = outputs of all neurons for one input sample.  \n",
    "This is exactly what we want to pass to the **next layer** as a batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc451905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape : (3, 4)\n",
      "weights shape: (3, 4)\n",
      "weights.T shape: (4, 3)\n",
      "layer_outputs:\n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n",
      "layer_outputs shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "inputs_arr = np.array(inputs)\n",
    "\n",
    "print(\"inputs shape :\", inputs_arr.shape)   # (3, 4)\n",
    "print(\"weights shape:\", weights.shape)      # (3, 4)\n",
    "print(\"weights.T shape:\", weights.T.shape)  # (4, 3)\n",
    "\n",
    "layer_outputs = np.dot(inputs_arr, weights.T) + biases\n",
    "\n",
    "print(\"layer_outputs:\\n\", layer_outputs)\n",
    "print(\"layer_outputs shape:\", layer_outputs.shape)  # (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004103a7",
   "metadata": {},
   "source": [
    "## How Biases Are Added for a Batch\n",
    "\n",
    "`biases` is a vector of shape $(3,)$ — one bias per neuron.\n",
    "\n",
    "After the matrix product, we have:\n",
    "\n",
    "- `np.dot(inputs, weights.T)` → shape $(3, 3)$\n",
    "\n",
    "When we add `biases` (shape $(3,)$) to this matrix, NumPy broadcasts\n",
    "the bias vector across **rows**:\n",
    "\n",
    "- bias[0] added to all outputs of neuron 0 (column 0)\n",
    "- bias[1] added to all outputs of neuron 1 (column 1)\n",
    "- bias[2] added to all outputs of neuron 2 (column 2)\n",
    "\n",
    "This matches what we want:\n",
    "\n",
    "> Each neuron’s bias is added to all of its outputs\n",
    "> across every sample in the batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b0e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product only:\n",
      " [[ 2.8   -1.79   1.885]\n",
      " [ 6.9   -4.81  -0.3  ]\n",
      " [-0.59  -1.949 -0.474]]\n",
      "\n",
      "With biases added:\n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "dot_only = np.dot(inputs_arr, weights.T)\n",
    "print(\"Dot product only:\\n\", dot_only)\n",
    "\n",
    "with_bias = dot_only + biases\n",
    "print(\"\\nWith biases added:\\n\", with_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3a9b1",
   "metadata": {},
   "source": [
    "## Big Picture\n",
    "\n",
    "We’ve now gone from:\n",
    "\n",
    "- **Single neuron, single sample**  \n",
    "  → dot(inputs, weights) + bias (scalar)\n",
    "\n",
    "to:\n",
    "\n",
    "- **Layer of neurons, single sample**  \n",
    "  → dot(weights, inputs) + biases (vector)\n",
    "\n",
    "to:\n",
    "\n",
    "- **Layer of neurons, batch of samples**  \n",
    "  → dot(inputs, weights.T) + biases (matrix)\n",
    "\n",
    "The pattern is the same:\n",
    "\n",
    "- linear combination (dot products)\n",
    "- plus bias\n",
    "- just scaled up to work on many samples at once.\n",
    "\n",
    "This is exactly how real neural networks operate internally:\n",
    "batches go in, batches of outputs come out.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
