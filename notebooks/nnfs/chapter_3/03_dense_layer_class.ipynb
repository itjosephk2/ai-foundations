{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00d9b9e",
   "metadata": {},
   "source": [
    "# NNFS – Chapter 3: Dense Layer Class\n",
    "\n",
    "In this notebook we follow the **Dense Layer Class** section of *Neural Networks from Scratch*.\n",
    "\n",
    "Goals:\n",
    "- Understand what a **dense (fully-connected) layer** is.\n",
    "- Implement a reusable `Layer_Dense` class with:\n",
    "  - random weight initialization\n",
    "  - zero biases\n",
    "  - a `forward` method that does the dot product + bias.\n",
    "- Use it to perform a forward pass on the spiral dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bad0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()  # seed, dtypes, and dot override for reproducibility\n",
    "\n",
    "np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616d6d1",
   "metadata": {},
   "source": [
    "## 1. What is a dense (fully-connected) layer?\n",
    "\n",
    "A **dense layer** (also called *fully-connected* or `fc` layer) is a layer where:\n",
    "\n",
    "- Every input is connected to **every neuron** in the layer.\n",
    "- Each connection has a **weight**.\n",
    "- Each neuron also has a **bias**.\n",
    "\n",
    "If we have:\n",
    "- `n_inputs` features coming in, and\n",
    "- `n_neurons` neurons in the layer,\n",
    "\n",
    "then the **weight matrix** will have shape `(n_inputs, n_neurons)` and the **bias vector** will\n",
    "have shape `(1, n_neurons)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4c4c2",
   "metadata": {},
   "source": [
    "## 2. Dense layer class skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b32bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer skeleton (with pass as placeholder)\n",
    "class Layer_Dense_Skeleton:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases later\n",
    "        pass\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases later\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106758a",
   "metadata": {},
   "source": [
    "## 3. Weight and bias initialization\n",
    "\n",
    "We will:\n",
    "- Initialize **weights** with small random values from a normal (Gaussian) distribution.\n",
    "- Initialize **biases** to zeros.\n",
    "\n",
    "Why random weights?\n",
    "- If all weights started as 0, every neuron in a layer would do the same thing.\n",
    "- Randomness breaks the symmetry and lets neurons learn different patterns.\n",
    "\n",
    "Why small values (e.g. multiplied by `0.01`)?\n",
    "- Very large initial weights can make training unstable or slow.\n",
    "- Small non-zero values give us a gentle starting point.\n",
    "\n",
    "### 3.1 Exploring `np.random.randn` and `np.zeros`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07bf9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random normal array (2 x 5):\n",
      "[[ 1.76405  0.40016  0.97874  2.24089  1.86756]\n",
      " [-0.97728  0.95009 -0.15136 -0.10322  0.4106 ]]\n",
      "\n",
      "Zeros array with shape (2, 5):\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random normal array (2 x 5):\")\n",
    "print(np.random.randn(2, 5))\n",
    "\n",
    "print(\"\\nZeros array with shape (2, 5):\")\n",
    "print(np.zeros((2, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6d027",
   "metadata": {},
   "source": [
    "### 3.2 Example: initialize weights and biases manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceaa0730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights example (shape (2, 4) ):\n",
      " [[ 0.00144  0.01454  0.00761  0.00122]\n",
      " [ 0.00444  0.00334  0.01494 -0.00205]]\n",
      "\n",
      "Biases example (shape (1, 4) ):\n",
      " [[0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 2\n",
    "n_neurons = 4\n",
    "\n",
    "weights_example = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "biases_example = np.zeros((1, n_neurons))\n",
    "\n",
    "print(\"Weights example (shape\", weights_example.shape, \"):\\n\", weights_example)\n",
    "print(\"\\nBiases example (shape\", biases_example.shape, \"):\\n\", biases_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551e541",
   "metadata": {},
   "source": [
    "## 4. Implementing the `Layer_Dense` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5695104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        # Shape of weights: (n_inputs, n_neurons)\n",
    "        # Shape of biases: (1, n_neurons)\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember inputs for potential later use (e.g. backprop)\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights, and biases\n",
    "        # inputs: (batch_size, n_inputs)\n",
    "        # weights: (n_inputs, n_neurons)\n",
    "        # result: (batch_size, n_neurons)\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8833cf8",
   "metadata": {},
   "source": [
    "## 5. Creating training data with `spiral_data`\n",
    "\n",
    "We'll create a 2D spiral dataset using `nnfs.datasets.spiral_data`:\n",
    "\n",
    "- `X` will have shape `(samples * classes, 2)` → 2 features (x₁, x₂).\n",
    "- `y` will be the class labels (0, 1, 2, ...).\n",
    "\n",
    "We then feed `X` into our dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc0c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (300, 2)\n",
      "y shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec24e3",
   "metadata": {},
   "source": [
    "## 6. Forward pass through the dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc16349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (300, 3)\n",
      "First 5 outputs:\n",
      " [[ 0.       0.       0.     ]\n",
      " [-0.00008  0.00003 -0.00006]\n",
      " [-0.00007  0.00005  0.00004]\n",
      " [-0.00021  0.00005 -0.00035]\n",
      " [-0.00024  0.00004 -0.00046]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "print(\"Output shape:\", dense1.output.shape)\n",
    "print(\"First 5 outputs:\\n\", dense1.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d469dea2",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "In this notebook we:\n",
    "- Reviewed what a **dense/fully-connected** layer is.\n",
    "- Talked about random weight initialization and zero biases.\n",
    "- Implemented a reusable `Layer_Dense` class using NumPy.\n",
    "- Generated a spiral dataset and ran it through our layer.\n",
    "\n",
    "Each row in `dense1.output` now represents the outputs of the 3 neurons in the layer\n",
    "for one input sample. Next steps in the book will add **activation functions** on top of\n",
    "these raw outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
